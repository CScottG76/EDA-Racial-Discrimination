{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examining Racial Discrimination in the US Job Market\n",
    "\n",
    "### Background\n",
    "Racial discrimination continues to be pervasive in cultures throughout the world. Researchers examined the level of racial discrimination in the United States labor market by randomly assigning identical résumés to black-sounding or white-sounding names and observing the impact on requests for interviews from employers.\n",
    "\n",
    "### Data\n",
    "In the dataset provided, each row represents a resume. The 'race' column has two values, 'b' and 'w', indicating black-sounding and white-sounding. The column 'call' has two values, 1 and 0, indicating whether the resume received a call from employers or not.\n",
    "\n",
    "Note that the 'b' and 'w' values in race are assigned randomly to the resumes when presented to the employer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"span5 alert alert-info\">\n",
    "### Exercises\n",
    "You will perform a statistical analysis to establish whether race has a significant impact on the rate of callbacks for resumes.\n",
    "\n",
    "Answer the following questions **in this notebook below and submit to your Github account**. \n",
    "\n",
    "   1. What test is appropriate for this problem? Does CLT apply?\n",
    "   2. What are the null and alternate hypotheses?\n",
    "   3. Compute margin of error, confidence interval, and p-value. Try using both the bootstrapping and the frequentist statistical approaches.\n",
    "   4. Write a story describing the statistical significance in the context or the original problem.\n",
    "   5. Does your analysis mean that race/name is the most important factor in callback success? Why or why not? If not, how would you amend your analysis?\n",
    "\n",
    "You can include written notes in notebook cells using Markdown: \n",
    "   - In the control panel at the top, choose Cell > Cell Type > Markdown\n",
    "   - Markdown syntax: http://nestacms.com/docs/creating-content/markdown-cheat-sheet\n",
    "\n",
    "\n",
    "#### Resources\n",
    "+ Experiment information and data source: http://www.povertyactionlab.org/evaluation/discrimination-job-market-united-states\n",
    "+ Scipy statistical methods: http://docs.scipy.org/doc/scipy/reference/stats.html \n",
    "+ Markdown syntax: http://nestacms.com/docs/creating-content/markdown-cheat-sheet\n",
    "+ Formulas for the Bernoulli distribution: https://en.wikipedia.org/wiki/Bernoulli_distribution\n",
    "</div>\n",
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Prior to determining which test to run, orienting to the data and/or preparing the data for analysis is important.</p>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import data\n",
    "data = pd.io.stata.read_stata('data/us_job_market_discrimination.dta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ad</th>\n",
       "      <th>education</th>\n",
       "      <th>ofjobs</th>\n",
       "      <th>yearsexp</th>\n",
       "      <th>honors</th>\n",
       "      <th>volunteer</th>\n",
       "      <th>military</th>\n",
       "      <th>empholes</th>\n",
       "      <th>occupspecific</th>\n",
       "      <th>...</th>\n",
       "      <th>compreq</th>\n",
       "      <th>orgreq</th>\n",
       "      <th>manuf</th>\n",
       "      <th>transcom</th>\n",
       "      <th>bankreal</th>\n",
       "      <th>trade</th>\n",
       "      <th>busservice</th>\n",
       "      <th>othservice</th>\n",
       "      <th>missind</th>\n",
       "      <th>ownership</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>316</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>313</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>313</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Nonprofit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  id ad  education  ofjobs  yearsexp  honors  volunteer  military  empholes  \\\n",
       "0  b  1          4       2         6       0          0         0         1   \n",
       "1  b  1          3       3         6       0          1         1         0   \n",
       "2  b  1          4       1         6       0          0         0         0   \n",
       "3  b  1          3       4         6       0          1         0         1   \n",
       "4  b  1          3       3        22       0          0         0         0   \n",
       "\n",
       "   occupspecific    ...      compreq  orgreq  manuf  transcom  bankreal trade  \\\n",
       "0             17    ...          1.0     0.0    1.0       0.0       0.0   0.0   \n",
       "1            316    ...          1.0     0.0    1.0       0.0       0.0   0.0   \n",
       "2             19    ...          1.0     0.0    1.0       0.0       0.0   0.0   \n",
       "3            313    ...          1.0     0.0    1.0       0.0       0.0   0.0   \n",
       "4            313    ...          1.0     1.0    0.0       0.0       0.0   0.0   \n",
       "\n",
       "  busservice othservice  missind  ownership  \n",
       "0        0.0        0.0      0.0             \n",
       "1        0.0        0.0      0.0             \n",
       "2        0.0        0.0      0.0             \n",
       "3        0.0        0.0      0.0             \n",
       "4        0.0        1.0      0.0  Nonprofit  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Orient to data\n",
    "data.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4870 entries, 0 to 4869\n",
      "Data columns (total 65 columns):\n",
      "id                    4870 non-null object\n",
      "ad                    4870 non-null object\n",
      "education             4870 non-null int8\n",
      "ofjobs                4870 non-null int8\n",
      "yearsexp              4870 non-null int8\n",
      "honors                4870 non-null int8\n",
      "volunteer             4870 non-null int8\n",
      "military              4870 non-null int8\n",
      "empholes              4870 non-null int8\n",
      "occupspecific         4870 non-null int16\n",
      "occupbroad            4870 non-null int8\n",
      "workinschool          4870 non-null int8\n",
      "email                 4870 non-null int8\n",
      "computerskills        4870 non-null int8\n",
      "specialskills         4870 non-null int8\n",
      "firstname             4870 non-null object\n",
      "sex                   4870 non-null object\n",
      "race                  4870 non-null object\n",
      "h                     4870 non-null float32\n",
      "l                     4870 non-null float32\n",
      "call                  4870 non-null float32\n",
      "city                  4870 non-null object\n",
      "kind                  4870 non-null object\n",
      "adid                  4870 non-null float32\n",
      "fracblack             4784 non-null float32\n",
      "fracwhite             4784 non-null float32\n",
      "lmedhhinc             4784 non-null float32\n",
      "fracdropout           4784 non-null float32\n",
      "fraccolp              4784 non-null float32\n",
      "linc                  4784 non-null float32\n",
      "col                   4870 non-null float32\n",
      "expminreq             4870 non-null object\n",
      "schoolreq             4870 non-null object\n",
      "eoe                   4870 non-null float32\n",
      "parent_sales          1672 non-null float32\n",
      "parent_emp            1722 non-null float32\n",
      "branch_sales          608 non-null float32\n",
      "branch_emp            658 non-null float32\n",
      "fed                   3102 non-null float32\n",
      "fracblack_empzip      1918 non-null float32\n",
      "fracwhite_empzip      1918 non-null float32\n",
      "lmedhhinc_empzip      1908 non-null float32\n",
      "fracdropout_empzip    1918 non-null float32\n",
      "fraccolp_empzip       1918 non-null float32\n",
      "linc_empzip           1918 non-null float32\n",
      "manager               4870 non-null float32\n",
      "supervisor            4870 non-null float32\n",
      "secretary             4870 non-null float32\n",
      "offsupport            4870 non-null float32\n",
      "salesrep              4870 non-null float32\n",
      "retailsales           4870 non-null float32\n",
      "req                   4870 non-null float32\n",
      "expreq                4870 non-null float32\n",
      "comreq                4870 non-null float32\n",
      "educreq               4870 non-null float32\n",
      "compreq               4870 non-null float32\n",
      "orgreq                4870 non-null float32\n",
      "manuf                 4870 non-null float32\n",
      "transcom              4870 non-null float32\n",
      "bankreal              4870 non-null float32\n",
      "trade                 4870 non-null float32\n",
      "busservice            4870 non-null float32\n",
      "othservice            4870 non-null float32\n",
      "missind               4870 non-null float32\n",
      "ownership             4870 non-null object\n",
      "dtypes: float32(42), int16(1), int8(12), object(10)\n",
      "memory usage: 1.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# Orient to data columns (names, type, complete data, etc)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6><b>1.  What test is appropriate for this problem?  Does CLT apply?</b></h6>\n",
    "\n",
    "<p> As the exercise sets a challenge to establish if race has a significant impact on callbacks for resumes, there are two notable areas to search for evidence:\n",
    "<ul>- Testing distrbutions by race to determine if *true* distributions are similar [or different], and</ul>\n",
    "<ul>- Determining if a relationship exists between variables \"call\" and \"race\".</ul></p>\n",
    "\n",
    "<p>Pursuing the first, the data may be separated into two sets, by race, and tested as a two sample test.  That said, options for testing are available:\n",
    "<ul>- A two sample permutation test offers a bootstrap method that will evaluate multiple permutations of the concatinated data.</ul>\n",
    "<ul>- A two sample z-test will compute a z-score representing the measurement of the relationship between a mean and group of data.  \n",
    "$$z = \\frac{\\left( \\mu_w - \\mu_b \\right) - \\Delta_{H_0}}{\\sqrt{\\mu\\left( 1 - \\mu \\right ) \\left ( \\frac{1}{n_w} + \\frac{1}{n_b}\\right)}},$$\n",
    "where $\\mu$ represents the mean of rate of calls.</ul></p>\n",
    "\n",
    "<p>According to the parameters of the exercise, the data consist of sets of identical resumes with names randomly applied.  The random sampling allows the treatement of the data as independent.  Furthermore, the independence, and reasonably large number, of samples allows treatment of the data as representative.  CLT applies.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create function to return permutation of data for hypothesis testing\n",
    "def permutation_sample(data1, data2):\n",
    "    \"\"\"Generate a permutation sample from two data sets\"\"\"\n",
    "    \n",
    "    data = np.concatenate((data1, data2))\n",
    "    permuted_data = np.random.permutation(data)\n",
    "    perm_sample_1 = permuted_data[:len(data1)]\n",
    "    perm_sample_2 = permuted_data[len(data1):]\n",
    "    \n",
    "    return perm_sample_1, perm_sample_2\n",
    "\n",
    "def draw_perm_reps(data_1, data_2, func, size=1):\n",
    "    \"\"\"Generate multipl permutation replicates\"\"\"\n",
    "    \n",
    "    perm_replicates = np.empty(size)\n",
    "    \n",
    "    for i in range(size):\n",
    "        perm_sample_1, perm_sample_2 = permutation_sample(data_1, data_2)\n",
    "        perm_replicates[i] = func(perm_sample_1, perm_sample_2)\n",
    "        \n",
    "    return perm_replicates\n",
    "\n",
    "# Test statistice for permutation test.\n",
    "def diff_of_means(data_1, data_2):\n",
    "    \"\"\"Difference in means of two arrays\"\"\"\n",
    "    \n",
    "    prop1 = np.mean(data_1)\n",
    "    prop2 = np.mean(data_2) \n",
    "    \n",
    "    diff = prop1 - prop2\n",
    "    \n",
    "    return abs(diff)\n",
    "\n",
    "# Two sample z test formula. \n",
    "def ztst_2samp(data1, data2, h_0):\n",
    "    \"\"\"Performs a 2 sample z-test, returning z-score and p-value\"\"\"\n",
    "    \n",
    "    d1m, d1n = np.mean(data1), len(data1)\n",
    "    d2m, d2n = np.mean(data2), len(data2)\n",
    "    mean = (np.sum(data1) + np.sum(data2)) / (len(data1) + len(data2))\n",
    "    \n",
    "    top = d1m - d2m - h_0 \n",
    "    bottom = mean * (1 - mean) * ((1/d1n) + (1/d2n))\n",
    "    \n",
    "    z = top / np.sqrt(bottom)\n",
    "    \n",
    "    if d1m >= d2m:\n",
    "        p = stats.norm.cdf(-z)*2\n",
    "    \n",
    "    else:\n",
    "        p = stats.norm.cdf(z)*2\n",
    "    \n",
    "    return z,p\n",
    "\n",
    "# Define functions for test stat data and margin of error\n",
    "def z_merci2(data1, data2, z_conf_int):\n",
    "    full = np.concatenate((data1, data2))\n",
    "    mean = np.mean(full)\n",
    "    diff = np.mean(data1) - np.mean(data2)\n",
    "    moe = z_conf_int * np.sqrt(mean * (1-mean) * ((1/len(data1)+(1/len(data2)))))\n",
    "    ci = (mean - diff) + np.array([-1, 1]) * moe\n",
    "    \n",
    "    return moe, ci, diff\n",
    "\n",
    "def perm_merci(perm_data, confidence):\n",
    "    \"\"\"Computes margin of error and confidence interval for permutation testing and confidence range.  \n",
    "    Enter confidence variable as a decimal value (e.g. 95% = .95)\"\"\"\n",
    "    \n",
    "    sem = abs(np.std(perm_data)) \n",
    "    moeh = np.mean(perm_data) + (sem * 2)\n",
    "    moel = np.mean(perm_data) - (sem * 2)\n",
    "    pctout = ((1 - confidence)/2)\n",
    "    pcth = (1 - pctout) * 100\n",
    "    pctl = (0 + pctout) * 100\n",
    "    pctci = np.percentile(perm_data,[pctl,pcth])\n",
    "    moe = sem * 2\n",
    "    sem2moe = [moel, moeh]\n",
    "    \n",
    "    return pctci, sem2moe, moe\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2435, 2435)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate data for comparison\n",
    "w = data[data.race=='w']\n",
    "b = data[data.race=='b']\n",
    "\n",
    "call_w = w['call']\n",
    "call_b = b['call']\n",
    "\n",
    "len(call_w), len(call_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6><b>2. What are the null and alternate hypotheses?</b></h6>\n",
    "\n",
    "<p>Both will be used to test the hypotheses: </p>\n",
    "$$H_0: \\mu_w = \\mu_b$$ \n",
    "$$H_A: \\mu_w \\ne \\mu_b$$\n",
    "\n",
    "<h6><b>3. Computer margin of error, confidence interval, and p-value. Try using both the bootstrapping and the frequentist statistical approaches.</b></h6>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate empirical difference of proportions\n",
    "emp_means_diff = diff_of_means(call_w, call_b)\n",
    "\n",
    "# Draw 10000 permutation replicates\n",
    "perm_replicates = draw_perm_reps(call_w, call_b, diff_of_means, size=10000)\n",
    "\n",
    "# Calculate & print p-value\n",
    "p_perm = np.sum(perm_replicates >= emp_means_diff) / len(perm_replicates)\n",
    "\n",
    "# Compute z & p values via z-test\n",
    "z,p = ztst_2samp(call_w, call_b, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Permuation Test Stats ---\n",
      "p-value:  0.0002\n",
      "Test-stat (diff of means):  0.03203285485506058\n",
      "confidence interval:  [ 0.          0.01724846]\n",
      "margin of error:  0.00941653672373\n",
      "confidence range (2SEM):  [-0.003234031413407148, 0.015599042034060779]\n",
      "--- z-test Stats ---\n",
      "p-value:  3.9838854095e-05\n",
      "z-score: 4.10841223524\n",
      "Test-stat:  0.03203285485506058\n",
      "95% confidence interval:  [ 0.03317805  0.06374187]\n",
      "margin of error :  0.0152819126334\n"
     ]
    }
   ],
   "source": [
    "# Calculate margin of error with 95% confidence interval\n",
    "permci, sem2, permoe = perm_merci(perm_replicates, 0.95)\n",
    "moci = z_merci2(call_w, call_b, 1.96)\n",
    "\n",
    "print('--- Permuation Test Stats ---')\n",
    "print('p-value: ',p_perm)\n",
    "print('Test-stat (diff of means): ', emp_means_diff)\n",
    "print('confidence interval: ', permci)\n",
    "print('margin of error: ', permoe)\n",
    "print('confidence range (2SEM): ', sem2)\n",
    "print('--- z-test Stats ---')\n",
    "print('p-value: ',p)\n",
    "print('z-score:',z)\n",
    "print('Test-stat: ', moci[2])\n",
    "print('95% confidence interval: ', moci[1])\n",
    "print('margin of error : ', moci[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<p><b><u>Permutation Test</b></u>:  With a p-value of zero, the null hypothesis that white and black sounding names have the same callback rate should be rejected.  Given the test statistic lies outside the 95% confidence interval, rejection of the null hypothesis is further supported.</p>\n",
    "\n",
    "<p><b><u>z-test</b></u>:  Similarly to the permutation test, the smallness of the p-value indicates it can be regarded as zero.  That said, the null hypothesis is rejected.  Whereas the test stat lies outside the confidence interval, further evidence is provided for rejection of the null hypthesis.</p>\n",
    "\n",
    "<p>Another test usefull in determining the relationships between variables would be the $\\chi^2$ test.  The claim of the null hypothesis, that distributions of callbacks for race are equal, is a claim that \"callback rate\" and \"race\" are variables independent from each other.  The $\\chi^2$ test will measure how well the null hypothesis fits the data.</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Power_divergenceResult(statistic=15.520408163265309, pvalue=8.1619303597043819e-05)\n"
     ]
    }
   ],
   "source": [
    "# Compute variables for test\n",
    "mcalls = np.sum(call_w) + np.sum(call_b)\n",
    "tcalls = len(call_w) + len(call_b)\n",
    "tprop = mcalls / tcalls\n",
    "\n",
    "obsv = [np.sum(call_w), np.sum(call_b)]\n",
    "expv = [tprop * len(call_w), tprop * len(call_b)]\n",
    "\n",
    "print(stats.chisquare(obsv, expv))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b><u>$\\chi^2$ test</b></u>: As expected, the p-value is practically zero; supporting rejection of the null hypothesis.</p>\n",
    "\n",
    "<h6><b>4. Write a story describing the statistical significance in the context of the original problem.</b></h6>\n",
    "\n",
    "<p>Attempting to examine levels of racial discrimination in the United States labor market, researchers assembled identical resumes and randomly assigned them white-sounding and black-sounding names.  Noting the callbacks associated with names, data were collected for examination.</p>\n",
    "\n",
    "<p>Three statistical testing methods were performed on the data under the assumption that callback rates for black-sounding names and white-sounding names were the same. A brief summary of the tests:\n",
    "\n",
    "<ul>- <b>Permutation Test</b>:  This test utilizes an approach similar to shuffling cards.  In effect, the data sets were shuffled together and randomly *redealt* a large number of times in order to simulate data recollection under identical circumstances.  The difference in callback rates were evaluated against the actual callback rate difference.  If given equal true callback rate distributions, the permutation test determined, with 95% confidence, the difference of callback rates would be between 0 and 0.018 callbacks per resume.  With an actual callback difference of 0.032 callbacks per resume, the probability of distributions including, at least, a 0.032 callback rate computes to practically zero.</ul>\n",
    "<ul>- <b>*z*-test</b>:  This test provides a quantification of a hypothetical mean value in relation to the group of data.  The computed z-score indicates the relationship in terms of standard deviation.  In normal distributions, approximately 95% of all values occur within 2 standard deviations.  In other words, if the callback rates have are equally distributed, the hypothetical mean will have a close relationship with the data resulting in a lower z-score.  In this case, the z-score of 4.1 indicates the data do not share a close relationship.  According to this test, with 95% confidence, the difference in mean callback rates would be between 0.33 and 0.64 callbacks per resume.  However close it seems, the actual difference in callback rates (0.032) lies outside the confidence range and the probability of distributions including, at least, a 0.032 callback rate also computes to practically zero.</ul>\n",
    "<ul>-<b>$\\chi^2$ test</b>: This test, also referred to as the Pearson $\\chi^2$ test, measures the relationship between variables.  Results from this test generally lend to an interpretation of indepence or dependence of variables.  As with the Pearson coefficient, divergence indicates the impact of relationship between variables; results nearest zero indicate variables are independent and vice versa.  In this case, if the callback rates are equally distributed, then there should be minimal impact and, therefore, a low divergence statistic.  The $\\chi^2$ test resulted in a divergence statistic of 15.5, indicating that callback rates and race are likely not independent variables.  That said, the probability of distributions showing independence with inclusion of, at least, a 0.032 callback rate computes, once again, to practically zero. </ul>\n",
    "\n",
    "\n",
    "<h6><b>5. Does your analysis mean that race/name is the most important factor in callback success?  Why or why not? If not, how would you amend  your analysis?</b></h6>\n",
    "\n",
    "<p>Each of the test models used indicated that callback rates for white-sounding names and black-sounding names were not similarly distributed.  However, while these tests may indicate that a statistical relationship may exist between callback rate and race, they do not provide enough evidence to suggest that race is the most important factor for callback success.  The scope of this exercise does not measure race against other factors for callback success, so a conclusion of race as the most important factor would be premature.</p>\n",
    "\n",
    "<p>According to Monster contributing writer, Catherine Conlan, resume attributes employers primarily look for are personal summary, skills/competencies, related experience, education, and presentation.  While names may act as indicators for race, it would be important to measure race against these factors before making any claim toward asserting \"most important factor\".</p> \n",
    "\n",
    "<p>The background information provides that identical resumes were assigned to white-sounding names and black-sounding names.  This would indicated that, within the data, duplicated resumes may be found in which related experience, skills, and education are equal.  If, in these cases, the only difference is race, then observations of callback rates may provide useful information.</p> \n",
    "\n",
    "#### Resources\n",
    "+ Article - 5 Critical Elements of any Resume: https://www.monster.com/career-advice/article/5-critical-elements-of-resume"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"span5 alert alert-success\">\n",
    "<h5><b>Additional Experimentation</b></h5>\n",
    "\n",
    "<p>What follows is a brief experiment regarding a potential direction of analysis of the impact of race and the success of callbacks.  Given that duplicate resumes are assumed to exist, samples will be drawn where duplicates will be weighed against each other.  The \"occupspecific\" category of the data appears to identify a resume entry akin to \"related experience\".  Samples will be drawn according to this parameter and duplicates within the samples will be identified for testing.</p>\n",
    "\n",
    "<p>Data collected will be tested using the three methods previously used and test the same hypothesis:\n",
    "$$H_0: \\mu_w = \\mu_b$$ \n",
    "$$H_A: \\mu_w \\ne \\mu_b$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 17, 316,  19, 313, 266,  13, 263, 379,  27,  21, 268, 267, 265,\n",
       "       317, 189, 185, 255, 323, 195, 329, 337, 326, 365,  34,  22, 229,\n",
       "       389, 387, 264, 214, 256, 374, 903, 274, 285, 253,  25, 448, 364,\n",
       "         7, 257, 443,  33, 307, 386, 785, 385, 233, 188,   8, 304, 461,\n",
       "       804, 338, 213, 269, 276,   9, 243, 234, 286])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simplify data into general resume entry categories\n",
    "dfdata = data[['education','yearsexp','empholes','occupspecific', 'occupbroad', 'sex','race', 'call']]\n",
    "\n",
    "dfdata['occupspecific'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create array for random sample selection.\n",
    "occupspecifics = [ 17, 316, 313, 266,  13, 263, 379,  27,  21, 268, 267, 317, 189,\n",
    "       185, 255, 323, 265, 195, 329, 337, 326,  34,  22, 229, 389, 365,\n",
    "       274, 285, 253,  19,  25, 387, 364,   7, 257, 443, 264,  33, 307,\n",
    "       386, 785, 385, 233, 188, 461, 448, 256,   8]\n",
    "\n",
    "# Randomly select three samples from data and assign as test data.\n",
    "selected = np.random.choice(occupspecifics,size=3)\n",
    "\n",
    "test1 = dfdata[dfdata['occupspecific']==selected[0]]\n",
    "test2 = dfdata[dfdata['occupspecific']==selected[1]]\n",
    "test3 = dfdata[dfdata['occupspecific']==selected[2]]\n",
    "\n",
    "# Inspect test data inormation \n",
    "#test1.info(), test2.info(), test3.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Identifies columns for duplicate matching criteria.\n",
    "columns = ['education', 'yearsexp', 'empholes', 'occupspecific', 'occupbroad']\n",
    "\n",
    "# Reduce test samples by rows having no duplicate rows per matching criteria\n",
    "test1 = test1[test1[columns].duplicated(keep=False)]\n",
    "test2 = test2[test2[columns].duplicated(keep=False)]\n",
    "test3 = test3[test3[columns].duplicated(keep=False)]\n",
    "\n",
    "# Store test sample arrays of indices of duplicated rows\n",
    "a = test1.groupby(columns).apply(lambda x: list(x.index)).tolist()\n",
    "b = test2.groupby(columns).apply(lambda x: list(x.index)).tolist()\n",
    "c = test3.groupby(columns).apply(lambda x: list(x.index)).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set  1\n",
      "w:b  [3 2]\n",
      "w:b  [4 3]\n",
      "w:b  [3]\n",
      "w:b  [14  6]\n",
      "w:b  [1 1]\n",
      "w:b  [4 1]\n",
      "w:b  [3 1]\n",
      "w:b  [5]\n",
      "w:b  [12 10]\n",
      "w:b  [2]\n",
      "w:b  [2]\n",
      "w:b  [1 1]\n",
      "\n",
      "Test set  2\n",
      "w:b  [17 15]\n",
      "\n",
      "Test set  3\n",
      "w:b  [15  7]\n",
      "w:b  [5 3]\n",
      "w:b  [2]\n"
     ]
    }
   ],
   "source": [
    "# Observe test data\n",
    "lets = [a,b,c]\n",
    "count = 1\n",
    "\n",
    "for x in lets:\n",
    "    print()\n",
    "    print('Test set ',count)\n",
    "    \n",
    "    for i,y in enumerate(x): \n",
    "        if x == a:\n",
    "            print('w:b ',np.array(data.iloc[y]['race'].value_counts()))\n",
    "        elif x == b:\n",
    "            print('w:b ',np.array(data.iloc[y]['race'].value_counts()))\n",
    "        else:\n",
    "            print('w:b ',np.array(data.iloc[y]['race'].value_counts()))\n",
    "    count = count + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w:b  46 33\n",
      "w:b  17 15\n",
      "w:b  20 12\n"
     ]
    }
   ],
   "source": [
    "# Organize data for testing.\n",
    "t1w = test1[test1['race']=='w']\n",
    "t1b = test1[test1['race']=='b']\n",
    "\n",
    "t2w = test2[test2['race']=='w']\n",
    "t2b = test2[test2['race']=='b']\n",
    "\n",
    "t3w = test3[test3['race']=='w']\n",
    "t3b = test3[test3['race']=='b']\n",
    "\n",
    "print('w:b ', len(t1w['race']), len(t1b['race'])) \n",
    "print('w:b ', len(t2w['race']), len(t2b['race'])) \n",
    "print('w:b ', len(t3w['race']), len(t3b['race']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"span5 alert alert-success\">\n",
    "<p>Observing the test sets indidicates that counts for duplication of resumes may not be an ideal 1:1 ratio.  In some cases, the duplicate resumes are present within one sample rather than both.  This could be further explored to establish if bias exists within the sets.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test stat 1 =  0.03491435945034027\n",
      "Test stat 2 =  0.11764705926179886\n",
      "Test stat 3 =  0.03431372344493866\n"
     ]
    }
   ],
   "source": [
    "# Set call data variables for functions\n",
    "call_t1w = t1w['call']\n",
    "call_t1b = t1b['call']\n",
    "call_t2w = t2w['call']\n",
    "call_t2b = t2b['call']\n",
    "call_t3w = t3w['call']\n",
    "call_t3b = t3b['call']\n",
    "\n",
    "# Calculate empirical difference of means\n",
    "pdf1 = diff_of_means(call_t1w, call_t1b)\n",
    "pdf2 = diff_of_means(call_t2w, call_t2b)\n",
    "pdf3 = diff_of_means(call_t2w, call_t3b)\n",
    "\n",
    "# Observe test stats to determine p-value calculations as > <\n",
    "print('Test stat 1 = ', pdf1)\n",
    "print('Test stat 2 = ', pdf2)\n",
    "print('Test stat 3 = ', pdf3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Draw 10000 permutation replicates\n",
    "t1reps = draw_perm_reps(call_t1w, call_t1b, diff_of_means, size=10000)\n",
    "t2reps = draw_perm_reps(call_t2w, call_t2b, diff_of_means, size=10000)\n",
    "t3reps = draw_perm_reps(call_t3w, call_t3b, diff_of_means, size=10000)\n",
    "\n",
    "# Compute p-values\n",
    "t1p = np.sum(t1reps >= pdf1) / len(t1reps)\n",
    "t2p = np.sum(t2reps >= pdf1) / len(t2reps)\n",
    "t3p = np.sum(t3reps >= pdf1) / len(t3reps)\n",
    "\n",
    "# Compute margin of error, confidence intervals, 2 SEM\n",
    "t1mci, t1sem2, t1moe = perm_merci(t1reps, 0.95)\n",
    "t2mci, t2sem2, t2moe = perm_merci(t2reps, 0.95)\n",
    "t3mci, t3sem2, t3moe = perm_merci(t3reps, 0.95)\n",
    "\n",
    "# Computer z-score & p values with z-test\n",
    "t1z, t1zp = ztst_2samp(call_t1w, call_t1b, 0)\n",
    "t2z, t2zp = ztst_2samp(call_t2w, call_t2b, 0)\n",
    "t3z, t3zp = ztst_2samp(call_t3w, call_t3b, 0)\n",
    "\n",
    "# Determine margin of error & confidence interval.\n",
    "merr1 = z_merci2(call_t1w, call_t1b, 1.96)\n",
    "merr2 = z_merci2(call_t2w, call_t2b, 1.96)\n",
    "merr3 = z_merci2(call_t2w, call_t3b, 1.96)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Permutation Test values ------\n",
      "******* Test 1 *******\n",
      "p-value:  0.6349\n",
      "Test-stat (diff of means):  0.03491435945034027\n",
      "confidence interval:  [ 0.0171278   0.12121212]\n",
      "bs margin of error:  0.054760256562\n",
      "****** Test 2 *******\n",
      "p-value: =  0.4898\n",
      "Test-stat (diff of means):  0.11764705926179886\n",
      "confidence interval:  [ 0.00784314  0.13333334]\n",
      "margin of error:  0.117179396432\n",
      "****** Test 3 ******\n",
      "p-value: =  1.0\n",
      "Test-stat (diff of means):  0.03431372344493866\n",
      "confidence interval:  [ 0.06666667  0.2       ]\n",
      "margin of error:  0.129248401292\n",
      "\n",
      "------ z Test values ------\n",
      "******* Test 1 *******\n",
      "p-value:  0.485139541397\n",
      "z-score:  0.69806020878\n",
      "Test-stat:  0.03491435945034027\n",
      "95% confidence interval:  [-0.08231331  0.11375042]\n",
      "margin of error=  0.0980318667021\n",
      "******* Test 2 *******\n",
      "p-value:  0.170066959863\n",
      "z-score:  1.37198868625\n",
      "Test-stat:  0.11764705926179886\n",
      "95% confidence interval:  [-0.22321567  0.11292155]\n",
      "margin of error=  0.16806861344\n",
      "******* Test 3 *******\n",
      "p-value:  0.580912400608\n",
      "z-score:  0.552052476266\n",
      "Test-stat:  0.03431372344493866\n",
      "95% confidence interval:  [-0.15592077  0.29418988]\n",
      "margin of error=  0.22505532659\n"
     ]
    }
   ],
   "source": [
    "print('------ Permutation Test values ------')\n",
    "print('******* Test 1 *******')\n",
    "print('p-value: ', t1p)\n",
    "print('Test-stat (diff of means): ', pdf1)\n",
    "print('confidence interval: ', t1mci)\n",
    "print('bs margin of error: ', t1moe)\n",
    "print('****** Test 2 *******')\n",
    "print('p-value: = ', t2p)\n",
    "print('Test-stat (diff of means): ', pdf2)\n",
    "print('confidence interval: ',t2mci)\n",
    "print('margin of error: ',t2moe)\n",
    "print('****** Test 3 ******')\n",
    "print('p-value: = ', t3p)\n",
    "print('Test-stat (diff of means): ', pdf3)\n",
    "print('confidence interval: ',t3mci)\n",
    "print('margin of error: ',t3moe)\n",
    "print()\n",
    "print('------ z Test values ------')\n",
    "print('******* Test 1 *******')\n",
    "print('p-value: ',t1zp )\n",
    "print('z-score: ',t1z)\n",
    "print('Test-stat: ', merr1[2])\n",
    "print('95% confidence interval: ', merr1[1])\n",
    "print('margin of error= ', merr1[0])\n",
    "print('******* Test 2 *******')\n",
    "print('p-value: ', t2zp)\n",
    "print('z-score: ',t2z)\n",
    "print('Test-stat: ', merr2[2])\n",
    "print('95% confidence interval: ', merr2[1])\n",
    "print('margin of error= ', merr2[0])\n",
    "print('******* Test 3 *******')\n",
    "print('p-value: ', t3zp)\n",
    "print('z-score: ', t3z)\n",
    "print('Test-stat: ', merr3[2])\n",
    "print('95% confidence interval: ', merr3[1])\n",
    "print('margin of error= ', merr3[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Power_divergenceResult(statistic=3.6826416337285899, pvalue=0.054981675065636892)\n",
      "Power_divergenceResult(statistic=1.8823529411764706, pvalue=0.17006696145390077)\n",
      "Power_divergenceResult(statistic=0.26666666666666666, pvalue=0.60557661633534621)\n"
     ]
    }
   ],
   "source": [
    "# Organize veariables to test for independence.\n",
    "mcalls1 = np.sum(call_t1w) + np.sum(call_t1b)\n",
    "mcalls2 = np.sum(call_t2w) + np.sum(call_t2b)\n",
    "mcalls3 = np.sum(call_t3w) + np.sum(call_t3b)\n",
    "\n",
    "tcalls1 = len(call_t1w) + len(call_t1b)\n",
    "tcalls2 = len(call_t3w) + len(call_t2b)\n",
    "tcalls3 = len(call_t3w) + len(call_t3b)\n",
    "\n",
    "tprop = mcalls1 / tcalls1\n",
    "tprop = mcalls2 / tcalls2\n",
    "tprop = mcalls3 / tcalls3\n",
    "\n",
    "obsv1 = [np.sum(call_t1w), np.sum(call_t1b)]\n",
    "obsv2 = [np.sum(call_t2w), np.sum(call_t2b)]\n",
    "obsv3 = [np.sum(call_t3w), np.sum(call_t3b)]\n",
    "\n",
    "expv1 = [tprop * len(call_t1w), tprop * len(call_t1b)]\n",
    "expv2 = [tprop * len(call_t2w), tprop * len(call_t2b)]\n",
    "expv3 = [tprop * len(call_t3w), tprop * len(call_t3b)]\n",
    "\n",
    "# Run chisquare function\n",
    "t1chi = stats.chisquare(obsv1, expv1)\n",
    "t2chi = stats.chisquare(obsv2, expv2)\n",
    "t3chi = stats.chisquare(obsv3, expv3)\n",
    "\n",
    "print(t1chi)\n",
    "print(t2chi)\n",
    "print(t3chi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"span5 alert alert-success\">\n",
    "<p>According to each of the testing methods, evidence exists to support the null hypothesis that distributions of white-sounding names are equal to black-sounding names.  In most cases, the test statistic fell within the respective 95% confidence range.  Furthermore, the $\\chi^2$ tests suggest independence of the callback rates and race when considered with other factors like education, skills and related experience.</p>\n",
    "\n",
    "<p>It can be noted that one of the $\\chi^2$ tests did show a divergence greater than 3 and p-value indicating probability of only 0.055 of the distribution including, at least, the test statistic.  While these results may not strongly support acceptance of the null hypothesis, they do not provide significant evidence to reject the null hypothesis.</p>\n",
    "\n",
    "<p>In each of these narrow test cases, it may be reasonable to conclude that, given equal skills, education, and related experience, race may not be the most important factor in callback success.  However, given the limits of the data provided, other factors may likely require exploration before drawing specific conclusions.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
